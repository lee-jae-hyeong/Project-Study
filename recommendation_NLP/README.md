# 개인프로젝트
### 1. 주제 : Amazon Reviews 데이터를 활용한 NLP 추천 모델링 구현
### 2. 프로젝트 기간 : Version1 (2021.06.01 ~ 2021.06.11) / Version2(추가 보완)
#
### 3. 주제 선정 이유 
- 이커머스나 OTT 등 추천 시스템은 매우 필수적인 요소가 되었기 때문에 아이템 기반의 협업 필터링 구현을 통해 사용자들에게 추천을 하기 위함.
- 아이템 기반 협업 필터링의 경우, 콜드 스타트 문제가 있어서 신규 고객이나 고객 행동 패턴이 거의 없을 경우에 적용하기엔 한계가 있음. 
- 내용 기반 추천 알고리즘과는 다른 새로운 추천 방식을 적용해보고자 NLP를 활용하여 추천 시스템을 구현하기 위함.
- NLP와 추천 시스템을 접목하여, 문제를 해결해볼 수 있지 않을까라는 생각에서 프로젝트를 진행하였음.
#  
### 4. 데이터 : Amazon Reviews Data 
- Feature data : train_data(40000 x 10), test_data(10000 x 10)
- URL : https://www.kaggle.com/kashnitsky/hierarchical-text-classification
#     
### 5. 활용 키워드 :
![image](https://user-images.githubusercontent.com/76590396/127207796-ca8201c5-ed94-46cc-a310-5ef56d44211d.png)
- Tool : Python, Tensorflow2, Scikit-learn, pandas, nltk 등
#  
### 6. 모델링 프로세스
![image](https://user-images.githubusercontent.com/76590396/127205894-3caa2d24-7efa-4f1a-a343-db822b5332fa.png)


#### 1. 아이템 기반 협업 필터링 : 제품 간의 평점을 바탕으로 코사인 유사도로 구현
#### 2. 아이템 기반 협업 필터링의 콜드 스타트 문제가 발생함. 유저들의 구매 데이터가 충분치 않기 때문.
#### 3. 신규 고객 혹은 구매 데이터가 적은 고객들에게 제품 추천을 해주기 위해, 리뷰 텍스트를 바탕으로 카테고리 예측 모델 구현
#### 4. 고객의 검색어, 문의 내용 등을 활용하여, 해당 고객이 관심이 있는 단어들을 통해 카테고리 예측함. 그리고 유저가 구매하지 않은 제품 중 제품 간의 유사도가 높은 상위 5개 제품을 추천해주는 방식으로 구현
#### 5. 카테고리별, 제품 간의 평균 평점에다가 누적 구매 수량을 100으로 나눈 값을 가중치로 더한 새로운 평점을 만듬.
#### 6. 카테고리별, 새로운 평점 상위 5개의 제품을 추천해줌

![image](https://user-images.githubusercontent.com/76590396/127203202-3157dae2-5ceb-4291-beb4-e369905d253a.png)
#### (위 이미지에 대한 참고 사항) New Rating = 새로운 평점 / Mean Ratning = 제품의 평균 평점 / Total Amount = 제품의 누적 판매 수량
### 7. 결과
#### 7-1.앙상블 모델 성능
![image](https://user-images.githubusercontent.com/76590396/127200424-3ee73e96-cbba-43dd-9a3a-3b87bd2e11f7.png)
- RFC(랜덤포레스트), RFC_CV(랜덤포레스트, GridSearchCV), XGB(XGBoost), XGB_CV(XGBoost, GridSearchCV)
- 앙상블의 공통적으로 들어간 요소 : Chi2, TF-IDF

#### 7-2.딥러닝 모델 성능
![image](https://user-images.githubusercontent.com/76590396/127201121-828f6530-4bad-4c39-9f47-015dc7e604a3.png)
- LSTM, LSTM with Attention, LSTM(Glove), BERT, LSTM(Glove) with attention, Seq2Seq(LSTM with attention)
- 결과 : 앙상블 모델과 딥러닝 모델 중, 가장 높은 성능을 보인 모델은 Sequence to Sequence 형태의 LSTM with Attention 모델로, 성능이 0.91이 나왔음.
![image](https://user-images.githubusercontent.com/76590396/127201253-a5b87f31-6a3d-4fbf-a240-036443d45be6.png)
![image](https://user-images.githubusercontent.com/76590396/127201284-6d20849d-799e-427f-aee2-289a5bca1d1d.png)
- epochs = 50, patience = 15로 학습을 진행하며 Early Stopping을 활용하였음.
- 그래서, 시각화 자료에서 도중에 끊긴 그래프들이 보임. 이는 Early Stopping으로 빠르게 손실이 최소화되는 구간을 찾았기 때문임.
#### 7-3. 평점 재조정으로 상위 5개 제품 추천
![image](https://user-images.githubusercontent.com/76590396/127204318-b4b88265-6ff0-4223-aa59-77baf0f2ea7b.png)
- 왼쪽 이미지는, 단순하게 평균 평점만으로 상위 5개 제품을 추천해준 것인데, 이러한 방식은 1명이 구매하고, 평점이 5점인 경우로만 나타나게 됨. 그러므로, 해당 평점에 대한 신뢰도가 다소 부족하다고 판단하였음.
- 그래서 누적 구매 수량을 가중치로 더하여, 오른쪽 이미지처럼 단순 평균 평점과 완전히 다른 신뢰도가 있는 상품을 추천해줄 수 있게 됨.
#
### 8. 결론
- 신규 고객에게도 검색어 하나만으로 추천을 해줄 수 있는 시스템을 구현하였다.
- 해당 추천 시스템에 대한 실효성은 A/B Test를 통해 기존 추천 시스템과 현재 적용하는 시스템을 비교하여 검증이 필요하다.
- 콜드 스타트의 문제점은 어느 정도 개선할 수 있는 방안이었지만, 롱테일 문제는 해결하지 못했다. 협업 필터링의 경우, 평점이 기재되지 않은 경우 추천 시스템 목록에도 등장하지 않고, 뿐만 아니라 인기가 좋은 상품을 추천해주는 방식은 굳이 추천 시스템으로 구현하지 않아도 된다는 점에서 이번에 구현한 방식은 많은 한계점이 따른다. 추천 시스템의 구현 방식은 너무나 다양하기 때문에, 이러한 부분들을 추가적으로 학습해나갈 필요성이 있다.
- 단순 분류 문제에 Attention 모델을 결합했을 경우, 성능이 개선이 되지 않는다는 것을 확인할 수 있었다. Attention의 매커니즘을 생각해보면 Seq2Seq의 형태에서, 디코더에서 출력되기 전에 인코더의 값을 참조하는 구조이지만, 단순 NLP 분류 문제에서는 크게 효과가 없는 것으로 판단하였다.(추가 검색을 해봤지만, 해당 내용은 나오지 않았음)
- 단순하게 Tensorflow의 임베딩을 쓰는 것보다, 사전 학습된 Glove를 썼을 때 안정적인 학습이 이루어지고 성능이 개선되는 것을 확인할 수 있었다.
- BERT의 경우, 기본적인 사전 학습 모델에다가 fine-tuning을 구현만했을 때 다른 모델과 유사한 성능이 나오는 것을 볼 수 있었다. 추가적으로 BERT에 대해 공부를 한 후, Setting 할 수 있는 방법과 다른 문제 형태를 풀어갈 때 어떻게 이용하면 좋을지 고민을 할 필요가 있다.
- 단순 분류 문제 형태로 접근했을 때, 기대하는 것보다 성능이 좋지 않다는 것을 느꼈다. 그래서 이전 프로젝트에서 진행했던 요약문 추출 모델을 다룰 때, 학습되는 라벨링에 따라 나오는 요약문이 매우 비슷하다는 것을 추론하여, Seq2Seq 모델로 접근을 해보기로 했다. 등장하는 Text들을 임베딩한 후, 라벨링을 특정 카테고리로 학습을 진행했고, 실제 다른 모델보다 확실하게 성능이 나오는 것을 볼 수 있었다. 이러한 방법으로 접근을 해도 되는지는 확실하게 알 수 없지만, 다른 관점으로 접근을 했을 때 성과가 나오는 것을 봤기 때문에 단순 분류 문제에서도 Seq2Seq 모델을 이용하여 하나의 Solution 모델로 이용해봐야겠다.
- 하이퍼파라미터에 튜닝에 따라 local minima로 추측되는 구간을 빠르게 나올 수 있는지 없는지 확인할 수 있었다. 예를 들어, 다른 Repo를 참고 할때, Optimizer로 RMSProp를 사용하였기 때문에, 동일하게 RMSProp를 이용했다. 하지만, local minima에서 나오지 못하고 초반 epochs을 많이 사용하게 되었고, 일정 시점이 지나면서 성능이 개선되는 것을 확인하였다. 그래서 모멘텀의 특징이 결합된다면 상대적으로 local minima를 빠르게 나올 수 있지 않을까라는 생각에 Adam을 이용했고, RMSProp보다 빠르게 개선되는 것을 확인하였다. 뿐만 아니라, Adam에서 학습률을 설정하여 과적합을 방지하여 일반화할 수 있다는 것도 볼 수 있었다. Batch Size에 따라서도, 성능 개선의 차이도 확인할 수 있었다. 이러한 과정들을 겪으면서 머신러닝을 다룰 때, 하이퍼파라미터 튜닝이 실제 모델의 성능 혹은 속도에서 차이가 있다는 것을 배웠고 조금 더 하이퍼 파라미터 튜닝과 개념을 명확하게 이해하여, 시기적절하게 사용해나가야겠다라고 생각했다. 
