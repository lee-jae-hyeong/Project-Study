|대주제|중주제|소주제|논문 이름|주소|코드|
|:----------------:|:----------------:|:----------------:|:----------------:|:----------------:|:----------------:|
|NLP|Embedding|Word2Vec|Efficient Estimation of Word Representations in Vector Space|||
|NLP|Embedding|FastText||||
|NLP|Embedding|Glove||||
|NLP|Embedding|ELMO||||
|NLP|Model/RNN|RNN||||
|NLP|Model/RNN|LSTM||||
|NLP|Model/RNN|GRU||||
|NLP|Model/RNN|Attention||||
|NLP|Model/Transformer|Transformer|Attention Is All You Need|https://arxiv.org/abs/1706.03762v5|https://github.com/tunz/transformer-pytorch/blob/e7266679f0b32fd99135ea617213f986ceede056/model/transformer.py#L201|
|NLP|Model/Transformer|GPT-1||||
|NLP|Model/Transformer|GPT-2||||
|NLP|Model/Transformer|GPT-3||||
|NLP|Model/Transformer|BERT|BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding|https://arxiv.org/abs/1810.04805v2|https://github.com/google-research/bert|
|NLP|Model/Transformer|RoBERTa||||
|NLP|Model/Transformer|XLNet||||
|NLP|Model/Transformer|ALBERT||||
|NLP|Model/Transformer|DistillBERT||||
