# 개인프로젝트
### 1. 주제 : Amazon Food Reviews 감성 분석 및 요약문 추출
### 2. 프로젝트 기간 : Version1 (2021.04.26 ~ 04.29) / Version2(두 차례 추가 보완)
#
### 3. 주제 선정 이유 
- 이전에 커머스 MD로 근무하면서, VOC나 고객 리뷰 등을 대략적으로 볼 수 있지만, 이를 자동적으로 분류하여 어떠한 부분이 이슈가 있는지 파악하는데 생각보다 많은 시간이 할애 되었음. 
- 그래서 이를 개선하여, 리뷰나 VOC의 요약문을 추출하고, 그 요약문이 해당하는 이슈사항을 카테고리별로 자동으로 분류할 수 있는 것을 구현할 수 있다면 업무 효율성을 높일 수 있을 것이라 생각했음.
- 구체적으로, 기업 측에서는 불필요한 인력 낭비를 줄일 수 있고, 고객님들이 어떠한 부분에서 불편함을 겪고 있는지 직관적으로 파악할 수 있어 이를 개선하는 활동을 우선순위에 따라 정할 수 있음.
- 4점 이하의 경우, 부정으로 분류할 수 있는 단어 혹은 문맥이 있을 것이라 판단하여 구분되는 특징이 있는지 가설 설정을 검정하고자 함.
#
### 4. 데이터 : Amazon Food Reviews
- Feature data : 568,454 x 10 (1999년 10월 - 2012년 10월의 리뷰 기재)
- URL : https://www.kaggle.com/snap/amazon-fine-food-reviews
#
### 5. 활용 키워드 
- EDA, Data Visualization, DL(LSTM, Attention, BERT, Transformer), ML(RandomForest, XGboost), SelectKBest(chi2) 등
#
### 6. 프로젝트 프로세스
![image](https://user-images.githubusercontent.com/76590396/127770884-0b36177b-4fef-4664-b769-c83e0689da9d.png)
- 6-1. 평점이 5점인 리뷰 텍스트는 긍정(1), 평점이 4점 이하인 리뷰 텍스트는 부정(0)으로 처리 후, 감성 분석 모델 구현
(평점 5점은 만족했거나 혹은 의미 없이 주는 점수라고 판단하여 긍정으로 처리, 평점이 4점 이하인 경우는 상품 및 서비스 등 부정적으로 느껴지는 요소가 하나라도 있었을 것이라 추축하여 부정으로 처리)
- 6-2. 부정으로 분류된 리뷰 텍스트들을 요약문 추출 모델에 투입
- 6-3. 요약문 추출 모델에서 나온 다양한 문제들을 세분화할 수 있는 부정 카테고리로 누적
- 6-4. 부정적인 요약문을 바탕으로 회사의 비즈니스 개선 및 업무 우선 순위 할당
#
### 7. 모델링
- 구현하고자 하는 모델 : NLP 감성 분석 및 NLP 요약문
- 감성 분석 : 앙상블 모델(XGB, RandomForest) - TF IDF, SelectKBest(Chi2) / 딥러닝 모델 - LSTM, BERT
- 요약문 모델 : Sequence to Sequence Model - LSTM with Attention / Transformer
#
### 8. 결과
#### - 감성 분석 모델
![image](https://user-images.githubusercontent.com/76590396/127770355-ace655e0-815d-4722-8edb-92393b54aaac.png)
![image](https://user-images.githubusercontent.com/76590396/127770444-648e9dd0-9dbd-4266-92f5-0902c3c5f92d.png)
#### - 감성 분석 모델 성능 비교
|감성 분석|LOSS|ACCURACY|
|:----------------:|:----------------:|:----------------:|
|LSTM|0.42|0.82|
|BERT|0.42|0.82|
|XGB|-|0.78|
|RFC|-||

#### - 요약문 모델
![image](https://user-images.githubusercontent.com/76590396/127770275-a45b006e-198a-4a02-b257-25f3332ec055.png)
![image](https://user-images.githubusercontent.com/76590396/127770195-c8952a83-0556-47a8-bc5d-49accd030cad.png)
#### - 요약문 모델 성능 비교
|요약문 모델|LOSS|ACCURACY|
|:----------------:|:----------------:|:----------------:|
|LSTM(Attention)|2.10|0.63|
|Transformer|1.99|0.68|
## 9. 결론
### 프로젝트에 대한 결론
- 감성 분석 모델의 경우, 5점과 4점이하로 나누는 다소 비선형적인 문제형태로 접근했지만, 0.81이라는 꽤나 높은 성능이 나왔다. 그러므로, 4점 이하의 경우 어느정도 부정적인 요소가 담겨진 내용이 있을 가능성이 있다라는 판단을 하였다. 부정적인 요소에 초점을 맞추는 것을 어느 정도 구별할 수 있다는 것으로 직접 비즈니스에 접목을 시켜보고 싶다.

- 요악문 모델의 경우, LSTM with Attention 모델로 구현했을 때 성능이 0.63으로 나와서 성능을 개선하고자 Transformer를 이용했다. 0.68정도로 다소 성능이 개선은 됐지만 실제 비즈니스에 적용할만큼의 일반화할 수 있는 모델은 아니라는 것을 확인할 수 있었다.(LSTM은 hidden state 벡터 길이가 고정되어 있어 가지고 있는 정보 손실이 발생할 수 있으므로, Transformer를 이용해주었다.)

- 해당 모델을 사용할 수는 없지만, 데이터 품질(부정적인 요소로 추출되는 라벨링)이 좋다면 성능이 개선이 되고, 실제 비즈니스에도 적용할 수 있지 않을까라는 생각을 했다. 

- 실제 커머스에선 VOC를 통해서 고객의 문의 사항에 대해서 라벨링된 데이터가 어느정도 적재가 되어 있는 것으로 알고 있다. 이러한 데이터를 활용하면 쉽게 데이터를 확보할 수 있을 것으로 생각한다.

### 느낀 점
- **EDA의 중요성** : Version 1과 Version2에서 성능이 차이가 나는 이유는 EDA와 전처리가 달라졌기 때문이다. Version1에서는 제대로 된 EDA 없이 모델링 구현에만 초점을 맞추다 보니, 전처리에서 문제가 발생하였다. 그래서 프로젝트를 보완해나가면서 Version2에서는 EDA를 처음부터 다시 시작하여 전처리를 해주었다. 해당 데이터의 경우, 중복 데이터가 많았기 때문에 이를 전처리 해주지 않았던 Version1에서는 감성 분석 모델, 요약문 모델 모두 성능이 Version2보다 높게 나온 것이었다. 이를 통해서 EDA가 얼마나 중요한지 느낄 수 있었다.

- **다양한 시도의 중요성1** : (첫번째 수정에 대한 의견)Version1에서는 시간이 부족하여 감성 분석의 경우, 다양한 모델을 구현하지 못했다. 그래서 Version2에서는 우선, 자연어 처리에 특화된 LSTM 모델로 우선 구현을 했다. 0.63으로 낮은 성능이 나와, 이를 개선해보고자 tf-idf로 앙상블 모델을 구현했지만 유사한 성능이 나왔다. 하지만 딥러닝에 비해 앙상블 모델이 확실하게 학습속도가 빠르다는 것을 느낄 수 있었다. 그렇다면, 내가 정의한 문제는 이 데이터로 해결할 수 없을까라는 고민을 했고 마지막으로 전이 학습을 통해 학습을 진행하면 성능이 달라지지 않을까라는 생각을 했다. 최근까지 성능이 잘 나온다고 알려진 BERT 모델로 구현을 해보기로 했다. 그 결과, 성능 개선이 약 0.18이나 개선되어 0.81이나 도달할 수 있었다. 이 과정을 통해 ML 모델과 DL 모델의 장단점을 명확하게 느낄 수 있었고, 데이터마다 그에 적합한 모델이 있을 수 있기 때문에 상황에 따라 다양한 모델을 시도해보고 좋은 성능이 나는 모델을 도출해내는 일련의 과정들이 필요하다고 느꼈다.

- **다양한 시도의 중요성2** : (두번째 수정에 대한 의견)Version1과 Version2를 거치면서, 성능을 높이기 위해서 여러 방법들을 조합할 수 있어야 한다는 것을 느낄 수 있었다. 첫번째로, 앙상블 모델의 경우, TF-IDF와 특이값 분해를 통해 SVD로 임베딩을 진행했을 때 성능이 0.64정도 밖에 나오지 않았지만 SVD 대신, 카이제곱검정을 이용했을 때 성능이 0.78정도로 성능이 개선되는 것을 볼 수 있었다. 두번째로, 딥러닝 모델의 경우, 초반에 성능이 개선되지 않는다면 local-minima에 빠져있을 수 있으므로 patience를 늘리고 batch size나 optimizer, 학습률 등을 조정하며 빠르게 개선될 수 있도록 튜닝이 필요하다는 것을 느꼈다. 마지막으로, BERT는 pretraning을 활용하다 보니 첫 epochs부터 높은 성능을 보여주는 것을 볼 수 있었다. 세 모델을 비교해보면 앙상블 모델은 카이제곱검정으로 성능을 높일 수 있었지만, 모든 변수들을 종속 변수와 일일이 비교하면서 상관성이 높은 것을 추출하려다 보니 교차 검증에서 너무 많은 시간이 걸렸다. LSTM은 가중치가 초기화된 상태로 학습을 처음에 진행하다보니 local-minima에 빠져서 초반에 개선되지 않는 현상이 있어서 학습 속도가 다소 늦어질 수 있었다. 그에 비해, BERT는 초반부터 최소점에 도달했기 때문에 가장 효율적이다라는 결론을 내릴 수 있었다.

- **GPU or TPU를 이용한 학습의 효율성** : 딥러닝 학습을 진행할 때, CPU를 쓸 떄는 1회 학습에 2~3시간 걸렸지만, GPU나 TPU를 썼을 땐, 1회 학습에 12분 정도밖에 걸리지 않았다. 이를 통해서 딥러닝 모델 구현을 할 땐, GPU나 TPU를 설정하여 쓰는 것의 중요성을 느꼈고, 분산 컴퓨팅을 왜 해야 하는지 느낄 수 있었다.

- **피드백의 중요성** : 프로젝트를 실시하고 거기에서 끝이 아니라 지속적으로 피드백 하는 과정이 필요하다는 것을 느꼈다. 단순하게 이 한개의 프로젝트를 수정하는 과정을 겪었지만, 이 과정에서 나는 부트캠프에서 강조하던 EDA와 모델 구현, 전처리의 중요성 등 다양한 것을 깨달았다. 앞으로도 프로젝트를 지속적으로 보완하고 인사이트를 넓히고 배우는 과정을 겪어가야겠다.

