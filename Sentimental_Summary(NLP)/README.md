# 개인프로젝트
## -Version1 (기초)
## -Version2 (보완)
### 1. 주제 : Amazon Food Reviews 감성 분석 및 요약문 추출
### 2. 주제 선정 이유 
#### - 이전에 커머스 MD로 근무하면서, VOC나 고객 리뷰 등을 대략적으로 볼 수 있지만, 이를 자동적으로 분류하여 어떠한 부분이 이슈가 있는지 파악하는데 생각보다 많은 시간이 할애 되었음. 
#### - 그래서 이를 개선하여, 리뷰나 VOC의 요약문을 추출하고, 그 요약문이 해당하는 이슈사항을 카테고리별로 자동으로 분류할 수 있는 것을 구현해볼 수 있다면 좋겠다라는 생각으로 시작하였음. 
#### - 이러한 시스템이 구현하게 된다면, 기업 측에서는 불필요한 인력 낭비를 줄일 수 있고, 고객님들이 어떠한 부분에서 불편함을 겪고 있는지 직관적으로 파악할 수 있어 이를 개선하는 활동을 우선순위에 따라 정할 수 있음.
### 3. 진행 기간 : 5일 프로젝트(Version1)
### 4. 데이터 : Amazon Food Reviews Data로 1999년 10월 - 2012년 10월의 리뷰 기재
#### - Feature data : 568,454 x 10
#### - URL : https://www.kaggle.com/snap/amazon-fine-food-reviews

### 5. 활용 키워드 : EDA, Data Visualization, DL(LSTM, Attention), ML(RandomForest, XGboost), Tensorflow  등

### 6. 모델링 프로세스
#### 평점이 5점인 리뷰의 경우 1로 치환, 평점이 4점 이하인 리뷰의 경우 0으로 치환하여 감성 분석 모델 구현 - ML과 DL 성능 비교 실시
#### 리뷰 텍스트를 Feature로 설정, 요약문을 label로 설정하여 LSTM with Attention 모델 구현
### 7. 가설 설정 : 5점인 경우, 부정적인 내용이 없으므로 긍정, 4점 이하의 경우, 부정적인 내용이 있을 가능성이 높으므로 부정으로 분류가 가능하다.

### 8. 모델 성능
#### - 감성 분석 모델(Accuracy 기준)
#### Version1 : LSTM Model(0.88)
#### Version2 : RadomForest(0.63), XGBoost(0.62), LSTM(0.63), BERT(0.81)
![image](https://user-images.githubusercontent.com/76590396/126628715-8dd320ff-0258-4972-97e1-f8fbb0984cfc.png)
##### BERT 모델 정확도 그래프
#### - 요약문 모델(Accuracy 기준)
#### 1. Version1 : LSTM with Attention(0.70)
#### 2. Version2 : LSTM with Attention(0.64)
## 9. 배운점
### - Version 1과 Version2에서 성능이 차이가 나는 이유는 EDA와 전처리가 달라졌기 때문이다. Version1에서는 제대로 된 EDA 없이 모델링 구현에만 초점을 맞추다 보니, 전처리에서 문제가 발생하였다. 그래서 프로젝트를 보완해나가면서 Version2에서는 EDA를 처음부터 다시 시작하여 전처리를 해주었다. 해당 데이터의 경우, 중복 데이터가 많았기 때문에 이를 전처리 해주지 않았던 Version1에서는 감성 분석 모델, 요약문 모델 모두 성능이 Version2보다 높게 나온 것이었다. 이를 통해서 EDA가 얼마나 중요한지 느낄 수 있었다.
### - Version1에서는 시간이 부족하여 감성 분석의 경우, 다양한 모델을 구현하지 못했다. 그래서 Version2에서는 우선, 자연어 처리에 특화된 LSTM 모델로 우선 구현을 했다. 0.63으로 낮은 성능이 나와, 이를 개선해보고자 tf-idf로 앙상블 모델을 구현했지만 유사한 성능이 나왔다. 하지만 딥러닝에 비해 앙상블 모델이 확실하게 학습속도가 빠르다는 것을 느낄 수 있었다. 그렇다면, 내가 정의한 문제는 이 데이터로 해결할 수 없을까라는 고민을 했고 마지막으로 전이 학습을 통해 학습을 진행하면 성능이 달라지지 않을까라는 생각을 했다. 최근까지 성능이 잘 나온다고 알려진 BERT 모델로 구현을 해보기로 했다. 그 결과, 성능 개선이 약 0.18이나 개선되어 0.81이나 도달할 수 있었다. 이 과정을 통해 ML 모델과 DL 모델의 장단점을 명확하게 느낄 수 있었고, 데이터마다 그에 적합한 모델이 있을 수 있기 때문에 상황에 따라 다양한 모델을 시도해보고 좋은 성능이 나는 모델을 도출해내는 일련의 과정들이 필요하다고 느꼈다.

### - Attention을 기반으로 한 요약문 모델의 경우, 내가 원하는 방향은 부정적인 문장에 초점을 맞추기를 바랬으나 라벨링(요약 문구)에 따라 학습되기 때문에 내가 생각한 의도와는 다른 문장들이 추출되었다. 부정적인 요소를 추출하는 요약문을 구현하기 위해선, 라벨링에서 부정적인 문장에 초점을 맞추는 내용들이 있어야 한다는 것을 느꼈다. (라벨링의 중요성을 느낌)

### - 딥러닝 학습을 진행할 때, CPU를 쓸 떄는 1회 학습에 2~3시간 걸렸지만, GPU나 TPU를 썼을 땐, 1회 학습에 12분 정도밖에 걸리지 않았다. 이를 통해서 딥러닝 모델 구현을 할 땐, GPU나 TPU를 설정하여 쓰는 것의 중요성을 느꼈고, 분산 컴퓨팅을 왜 해야 하는지 느낄 수 있었다.

### - 프로젝트를 실시하고 거기에서 끝이 아니라 지속적으로 피드백 하는 과정이 필요하다는 것을 느꼈다. 단순하게 이 한개의 프로젝트를 수정하는 과정을 겪었지만, 이 과정에서 나는 부트캠프에서 강조하던 EDA와 모델 구현, 전처리의 중요성 등 다양한 것을 깨달았다. 앞으로도 프로젝트를 지속적으로 보완하고 인사이트를 넓히고 배우는 과정을 겪어가야겠다.


### 10. 결론

#### 감성 분석 모델의 경우, 5점과 4점이하로 나누는 다소 비선형적인 문제형태로 접근했지만, 0.81이라는 꽤나 높은 성능이 나왔다. 부정적인 요소에 초점을 맞추는 것을 어느 정도 구별할 수 있다는 것으로 직접 비즈니스에 접목을 시켜보고 싶다.
#### 요약문 모델의 경우, 일반화할 수 있을만큼의 성능이 나오지 않았다. 그래서 해당 모델을 사용할 수는 없지만, 데이터 품질(부정적인 요소로 추출되는 라벨링)이 좋다면 성능이 개선되지 않을까라는 생각을 했다. 그리고 시간이 된다면 Transformer 모델을 구현해봄으로써 문장이 길어지는 것도 요약할 수 있을 것이라 기대한다.

